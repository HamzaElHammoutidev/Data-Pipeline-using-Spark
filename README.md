# Data Pipeline using Spark 

US Immigration data pipeline from different sources using Schema-on-read on Spark for processing large files [/data]: 
 
 - Files Types : 
	 - .dat 
	 - .csv 
	 - .parquet [sas data]
	 
 - Steps : 
    - Step 1
    - Step 2 
    - Step 3 
    - Step 4
    
# Datasets : 
![Data Lineage](https://github.com/HamzaElHammoutidev/Data-Pipeline-using-Spark/blob/master/SourcesImage.png)
